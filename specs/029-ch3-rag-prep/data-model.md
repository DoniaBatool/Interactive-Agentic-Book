# Data Model: Chapter 3 — RAG + Embedding Preparation Layer

**Feature**: 029-ch3-rag-prep
**Date**: 2025-01-27
**Purpose**: Define data structures and entities for Chapter 3 RAG operations

## Overview

This document defines the data structures, entities, and relationships for Chapter 3 RAG operations: chunking, embeddings, Qdrant collections, and retrieval pipeline. All structures are placeholders with TODO markers for future implementation.

## Entities

### 1. Chapter 3 Chunk

**Storage**: Python module `backend/app/content/chapters/chapter_3_chunks.py`

**Constant**: `CH3_CHUNKS = []` (placeholder)

**Structure**:
```python
{
    "id": str,                    # Unique chunk ID (e.g., "ch3-s1-c0")
    "text": str,                  # Chunk text content
    "chapter_id": int,            # Chapter identifier (always 3)
    "section_id": str,            # Section identifier (e.g., "what-is-perception-in-physical-ai")
    "position": int,              # Position in chapter (0-based)
    "word_count": int,            # Word count in chunk
    "metadata": {
        "heading": str,          # Section heading (e.g., "What Is Perception in Physical AI?")
        "type": str,             # Content type: "paragraph", "heading", "glossary", "code", "diagram"
        "has_diagram": bool,     # True if section has diagram placeholder
        "has_ai_block": bool,    # True if section has AI block
        "chunk_markers": bool,   # True if chunk has RAG-CHUNK markers
        "concepts": List[str]    # Physical AI concepts (e.g., ["perception", "sensors", "vision", "signal-processing"])
    }
}
```

**Function**:
```python
def get_chapter_chunks(chapter_id: int = 3) -> List[Dict[str, Any]]:
    """
    Return list of text chunks from Chapter 3 with metadata.
    
    Chunks respect chunk markers (CHUNK: START / CHUNK: END) and RAG-CHUNK markers.
    
    TODO: Implement chunking from Chapter 3 MDX content
    TODO: Load Chapter 3 content from frontend/docs/chapters/chapter-3.mdx
    TODO: Implement chunking strategy:
        - Respect chunk markers (CHUNK: START / CHUNK: END)
        - Respect RAG-CHUNK markers (<!-- RAG-CHUNK: start --> / <!-- RAG-CHUNK: end -->)
        - Section-based logical chunks (each H2 section is a natural chunk boundary)
        - Semantic segmentation by section
        - Heading-aware slicing (respect H2 boundaries)
        - Max token size constraints (e.g., 512 tokens per chunk)
        - Overlapping window strategy (e.g., 50 tokens overlap)
    TODO: Extract metadata (section titles, positions, word counts)
    TODO: Generate unique chunk IDs (format: "ch3-s{section}-c{chunk}")
    TODO: Handle special content (glossary, diagrams, AI blocks)
    TODO: Include Physical AI-specific metadata (concepts: perception, sensors, vision, signal processing)
    TODO: Include chunk marker metadata (chunk_markers: bool flag)
    """
    return []  # Placeholder
```

**Validation**:
- Function must exist and be importable
- Function signature must match pattern
- Return type must be `List[Dict[str, Any]]`
- Placeholder return acceptable (empty list)

**Relationship**: 1:N with Chapter 3 Content (future: multiple chunks per chapter)

---

### 2. Embedding Vector

**Storage**: Generated by `backend/app/ai/embeddings/embedding_client.py`

**Structure**:
```python
# Single embedding
embedding: List[float]           # [0.123, -0.456, 0.789, ...]
                                 # Dimension: 1536 (for text-embedding-3-small)

# Batch embeddings
embeddings: List[List[float]]    # [[0.123, ...], [0.456, ...], ...]
```

**Functions**:
```python
def embed_chapter3_chunks(chunks: List[str]) -> List[List[float]]:
    """
    Generate batch embeddings for Chapter 3 chunks.
    
    TODO: Implement batch embedding for Chapter 3 chunks
    TODO: Use CH3_EMBEDDING_MODEL for Chapter 3
    TODO: Use settings.ch3_embedding_model for model selection
    TODO: Use batch API endpoint for efficiency
    TODO: Handle large batches (split if needed, e.g., 100 chunks per batch)
    TODO: Add progress tracking for large batches
    TODO: Add error handling for partial failures
    TODO: Return list of 1536-dimensional vectors
    """
    return []  # Placeholder

def normalize_chapter3_embeddings(embeddings: List[List[float]]) -> List[List[float]]:
    """
    Normalize Chapter 3 embeddings (optional L2 normalization).
    
    TODO: Implement normalization for Chapter 3 embeddings
    TODO: Optional L2 normalization
    TODO: Return normalized embeddings
    """
    return []  # Placeholder
```

**Model Configuration**:
- **Name**: "text-embedding-3-small" (from EMBEDDING_MODEL_CH3 env var)
- **Provider**: OpenAI (TODO: support Gemini)
- **Dimensions**: 1536
- **Max Tokens**: 8191

**Validation**:
- Functions must exist and be importable
- Function signatures must match pattern
- Return types must match (List[List[float]])
- Placeholder returns acceptable (empty lists)

**Relationship**: 1:1 with Chapter 3 Chunk (one embedding per chunk)

---

### 3. Qdrant Collection: chapter3

**Storage**: Qdrant vector database (collection: "chapter3")

**Collection Configuration**:
- **Name**: "chapter3" (from QDRANT_COLLECTION_CH3 env var)
- **Vector Dimension**: 1536
- **Distance Metric**: Cosine similarity
- **Index**: HNSW (m, ef_construct parameters)

**Vector Document Structure**:
```python
{
    "id": str,                    # Unique document ID (e.g., "ch3-s1-c0")
    "vector": List[float],        # Embedding vector (1536 dimensions)
    "payload": {
        "text": str,              # Original text chunk
        "chapter_id": int,        # Chapter identifier (3)
        "section_id": str,        # Section identifier
        "position": int,          # Position in chapter
        "word_count": int,        # Word count
        "metadata": {
            "heading": str,
            "type": str,
            "has_diagram": bool,
            "has_ai_block": bool,
            "concepts": List[str],
            "chunk_markers": bool
        }
    }
}
```

**Functions**:
```python
# In qdrant_store.py
def create_collection(collection_name: str) -> bool:
    """
    Create Qdrant collection for chapter content.
    
    TODO: For Chapter 3: collection_name = "chapter3" (from QDRANT_COLLECTION_CH3 env var)
    TODO: Configure collection with appropriate vector size (1536 for text-embedding-3-small)
    TODO: Set distance metric to Cosine similarity
    TODO: Configure HNSW index (m, ef_construct parameters)
    """
    return False  # Placeholder

def similarity_search_ch3(query: str, top_k: int = 5) -> List[Dict[str, Any]]:
    """
    Perform similarity search in Chapter 3 Qdrant collection.
    
    TODO: Implement similarity search for Chapter 3
    TODO: Use collection "chapter3" (from QDRANT_COLLECTION_CH3 env var)
    TODO: Embed query using generate_embedding(query, chapter_id=3)
    TODO: Perform vector search in Qdrant
    TODO: Return top-k most relevant chunks
    """
    return []  # Placeholder
```

**Validation**:
- Functions must exist and be importable
- Function signatures must match pattern
- Placeholder returns acceptable (False, empty list)

**Relationship**: 1:N with Chapter 3 Chunk (multiple chunks per collection)

---

### 4. RAG Pipeline Response

**Storage**: Generated by `backend/app/ai/rag/ch3_pipeline.py`

**Structure**:
```python
{
    "context": str,                    # Assembled context string from retrieved chunks
    "chunks": List[Dict[str, Any]],   # Retrieved chunks with metadata
    "query_embedding": List[float]    # Query embedding vector
}
```

**Function**:
```python
async def run_ch3_rag_pipeline(query: str, top_k: int = 5) -> Dict[str, Any]:
    """
    Execute RAG pipeline for Chapter 3: retrieve → embed → search → context → response.
    
    Pipeline Steps (all TODO):
    1. Retrieve chunks (call get_chapter_chunks(chapter_id=3))
    2. Embed query (call generate_embedding(query, chapter_id=3))
    3. Perform search (call similarity_search_ch3(query, top_k))
    4. Construct retrieval context (assemble retrieved chunks into context string)
    5. Return placeholder response (return context dictionary)
    
    TODO: Implement all RAG pipeline steps
    TODO: Chapter 3 specific flow
    TODO: Error handling
    TODO: Context size limits
    """
    return {
        "context": "",
        "chunks": [],
        "query_embedding": []
    }  # Placeholder
```

**Validation**:
- Function must exist and be importable
- Function signature must match pattern
- Return type must be `Dict[str, Any]`
- Placeholder return acceptable (empty dict with keys)

**Relationship**: 1:1 with User Query (one response per query)

---

## Relationships

### Chapter 3 Content → Chunks
- **Type**: 1:N (one chapter, multiple chunks)
- **Source**: `chapter_3_chunks.py`
- **Function**: `get_chapter_chunks(chapter_id=3)`

### Chapter 3 Chunks → Embeddings
- **Type**: 1:1 (one chunk, one embedding)
- **Source**: `embedding_client.py`
- **Function**: `embed_chapter3_chunks(chunks)`

### Chapter 3 Embeddings → Qdrant Collection
- **Type**: N:1 (multiple embeddings, one collection)
- **Source**: `qdrant_store.py`
- **Function**: `upsert_vectors(collection_name="chapter3", vectors)`

### User Query → RAG Pipeline Response
- **Type**: 1:1 (one query, one response)
- **Source**: `ch3_pipeline.py`
- **Function**: `run_ch3_rag_pipeline(query, top_k)`

## Notes

- All structures are placeholders with TODO markers
- No real RAG/LLM logic implemented
- Structure only, no implementation details
- Follows Chapter 2 RAG prep patterns (Feature 012 or 021)

