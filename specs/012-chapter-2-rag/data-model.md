# Data Model: Chapter 2 RAG Chunking, Embeddings & Qdrant Collection Setup

**Feature**: 012-chapter-2-rag
**Date**: 2025-12-05
**Purpose**: Define data structures and entities for Chapter 2 RAG operations

## Overview

This document defines the data structures, entities, and relationships for Chapter 2 RAG operations: chunking, embeddings, Qdrant collections, and retrieval pipeline. All structures are placeholders with TODO markers for future implementation.

## Entities

### 1. Chapter 2 Chunk

**Storage**: Python module `backend/app/content/chapters/chapter_2_chunks.py`

**Structure**:
```python
{
    "id": str,                    # Unique chunk ID (e.g., "ch2-s1-c0")
    "text": str,                  # Chunk text content
    "chapter_id": int,            # Chapter identifier (always 2)
    "section_id": str,            # Section identifier (e.g., "introduction-to-ros2")
    "position": int,              # Position in chapter (0-based)
    "word_count": int,            # Word count in chunk
    "metadata": {
        "heading": str,          # Section heading (e.g., "Introduction to ROS 2")
        "type": str,             # Content type: "paragraph", "heading", "glossary", "code", "diagram"
        "has_diagram": bool,     # True if section has diagram placeholder
        "has_ai_block": bool,    # True if section has AI block
        "ros2_concepts": List[str],  # ROS 2 concepts in chunk (e.g., ["nodes", "topics"])
        "difficulty": str         # Difficulty level: "beginner", "intermediate", "advanced"
    }
}
```

**Function**:
```python
def get_chapter_chunks(chapter_id: int = 2) -> List[Dict[str, Any]]:
    """
    TODO: Implement chunking from Chapter 2 MDX content
    TODO: Load Chapter 2 content from frontend/docs/chapters/chapter-2.mdx
    TODO: Implement chunking strategy:
        - Max token size constraints
        - Semantic segmentation by section
        - Heading-aware slicing
        - Overlapping window strategy
    """
    return []  # Placeholder
```

**Validation**:
- Function must exist and be importable
- Function signature must match pattern
- Return type must be `List[Dict[str, Any]]`
- Placeholder return acceptable (empty list)

**Relationship**: 1:N with Chapter 2 Content (future: multiple chunks per chapter)

---

### 2. Embedding Vector

**Storage**: Generated by `backend/app/ai/embeddings/embedding_client.py`

**Structure**:
```python
# Single embedding
embedding: List[float]           # [0.123, -0.456, 0.789, ...]
                                 # Dimension: 1536 (for text-embedding-3-small)

# Batch embeddings
embeddings: List[List[float]]    # [[0.123, ...], [0.456, ...], ...]
```

**Functions**:
```python
def generate_embedding(text: str) -> List[float]:
    """
    TODO: Implement embedding generation using configured embedding model
    TODO: Use settings.embedding_model for model selection
    TODO: Use OpenAI embeddings API or other embedding service
    """
    return []  # Placeholder

def batch_embed(chunks: List[str]) -> List[List[float]]:
    """
    TODO: Implement batch embedding generation
    TODO: Use batch API endpoint for efficiency
    TODO: Handle large batches (split if needed)
    """
    return []  # Placeholder
```

**Model Configuration**:
- **Name**: "text-embedding-3-small" (from EMBEDDING_MODEL env var)
- **Provider**: OpenAI (TODO: support Gemini)
- **Dimensions**: 1536
- **Max Tokens**: 8191

**Validation**:
- Functions must exist and be importable
- Return types must match signatures
- Placeholder returns acceptable (empty lists)

**Relationship**: 1:1 with Chunk (each chunk has one embedding vector)

---

### 3. Qdrant Vector Document

**Storage**: Qdrant collection "chapter_2"

**Structure**:
```python
{
    "id": str,                    # Same as chunk ID (e.g., "ch2-s1-c0")
    "vector": List[float],        # Embedding vector (1536 dimensions)
    "payload": {
        "text": str,              # Original text chunk
        "chapter_id": int,        # Chapter identifier (2)
        "section_id": str,        # Section identifier
        "position": int,         # Position in chapter
        "word_count": int,       # Word count
        "metadata": {
            "heading": str,
            "type": str,
            "has_diagram": bool,
            "has_ai_block": bool,
            "ros2_concepts": List[str],
            "difficulty": str
        }
    }
}
```

**Collection Schema**:
```python
{
    "name": "chapter_2",           # Collection name (from QDRANT_COLLECTION_CH2)
    "vector_size": 1536,          # Vector dimensions
    "distance": "Cosine",         # Distance metric
    "hnsw_config": {              # HNSW index configuration (TODO)
        "m": int,                 # Number of connections
        "ef_construct": int      # Size of dynamic candidate list
    }
}
```

**Functions**:
```python
def create_collection(collection_name: str) -> bool:
    """
    TODO: Create Qdrant collection for chapter content
    TODO: Use settings.qdrant_url and settings.qdrant_api_key
    TODO: Configure collection with appropriate vector size
    """
    return False  # Placeholder

def upsert_vectors(
    collection_name: str,
    vectors: List[Dict[str, Any]]
) -> bool:
    """
    TODO: Insert or update vectors in Qdrant collection
    TODO: Use Qdrant client to batch upsert vectors
    TODO: Handle large batches (split if needed)
    """
    return False  # Placeholder

def similarity_search(
    collection_name: str,
    query: str,
    top_k: int = 5
) -> List[Dict[str, Any]]:
    """
    TODO: Perform similarity search in Qdrant collection
    TODO: Embed query text using embedding_client.generate_embedding()
    TODO: Use Qdrant client to perform vector search
    """
    return []  # Placeholder
```

**Validation**:
- Functions must exist and be importable
- Return types must match signatures
- Placeholder returns acceptable

**Relationship**: 1:1 with Embedding Vector (each vector stored as Qdrant document)

---

### 4. RAG Pipeline Context

**Storage**: Returned by `backend/app/ai/rag/pipeline.py`

**Structure**:
```python
{
    "context": str,                    # Assembled context string
    "chunks": List[Dict[str, Any]],   # Retrieved chunks with metadata
    "query_embedding": List[float]     # Query embedding vector
}
```

**Function**:
```python
async def run_rag_pipeline(
    query: str,
    chapter_id: int,
    top_k: int = 5
) -> Dict[str, Any]:
    """
    Pipeline Steps (all TODO):
    1. Load chunks (call get_chapter_chunks(chapter_id=2))
    2. Embed query (call generate_embedding(query))
    3. Perform search (call similarity_search(collection="chapter_2", query_embedding, top_k))
    4. Build context (assemble retrieved chunks into context string)
    5. Return context (pass context to runtime engine)
    """
    return {
        "context": "",
        "chunks": [],
        "query_embedding": []
    }  # Placeholder
```

**Context Assembly (TODO)**:
- Strategy: Concatenate chunks in order of similarity score
- Max Context: Configurable (default: 4 chunks from RAG_MAX_CONTEXT)
- Section Headers: Include section headers in context
- Metadata: Include chunk metadata in context string

**Validation**:
- Function must exist and be importable
- Return type must match signature
- Placeholder return acceptable

**Relationship**: N:1 with Runtime Engine (multiple queries → one context per query)

---

### 5. Runtime Engine Knowledge Source Mapping

**Storage**: Python module `backend/app/ai/runtime/engine.py`

**Structure**:
```python
# Knowledge source mapping
knowledge_sources = {
    1: "chapter_1_chunks",  # Existing
    2: "chapter_2_chunks",  # NEW for Chapter 2
}

# TODO: Chapter 2 (ROS 2) RAG Integration
# When chapterId=2:
#   1. Import get_chapter_chunks from app.content.chapters.chapter_2_chunks
#   2. Call get_chapter_chunks(chapter_id=2) to retrieve Chapter 2 chunks
#   3. Use chunks for RAG retrieval (semantic search in Qdrant)
#   4. Filter chunks by section_id when sectionId provided in request
#   5. Pass Chapter 2 context (chunks + metadata) to subagents
#   6. Subagents will use ROS 2-specific context for LLM prompts:
#      - ROS 2 concepts: nodes, topics, services, actions, packages, launch-files
#      - ROS 2 analogies: post office, restaurant, phone calls, package delivery
#      - ROS 2 examples: TurtleBot 3, navigation stack, robot arm control
```

**Validation**:
- Mapping must exist for chapterId=2
- TODO comments must explain RAG integration flow
- Placeholder logic acceptable

**Relationship**: 1:1 with Chapter 2 Chunks (mapping → chunks function)

---

### 6. Environment Variables

**Storage**: `.env.example` and `.env` files

**Structure**:
```bash
# Chapter 2 RAG Configuration
QDRANT_COLLECTION_CH2="chapter_2"           # Qdrant collection name for Chapter 2
EMBEDDING_MODEL="text-embedding-3-small"     # Embedding model name
RAG_MAX_CONTEXT=4                            # Maximum number of chunks in context
```

**Validation**:
- Variables must be documented in `.env.example`
- Descriptions must be clear
- Placeholder values must be provided

**Relationship**: N:1 with RAG Pipeline (multiple env vars → one pipeline config)

## Relationships

### Entity Relationship Diagram

```
Chapter 2 Content (MDX)
    ↓ (chunking)
Chapter 2 Chunk
    ↓ (embedding)
Embedding Vector
    ↓ (upsert)
Qdrant Vector Document
    ↓ (similarity search)
RAG Pipeline Context
    ↓ (pass to)
Runtime Engine
    ↓ (pass to)
Subagents → LLM Provider
```

### Data Flow

1. **Chunking**: Chapter 2 MDX content → Chapter 2 Chunks
2. **Embedding**: Chapter 2 Chunks → Embedding Vectors
3. **Storage**: Embedding Vectors → Qdrant Vector Documents
4. **Retrieval**: User Query → Embedding Vector → Similarity Search → Retrieved Chunks
5. **Context Assembly**: Retrieved Chunks → RAG Pipeline Context
6. **LLM Integration**: RAG Pipeline Context → Runtime Engine → Subagents → LLM Provider

## Validation Rules

### Chunk Validation
- `id` must be unique (format: "ch2-s{section}-c{chunk}")
- `chapter_id` must be 2
- `section_id` must match section anchors from chapter-2.mdx
- `text` must be non-empty (when implemented)
- `metadata` must include required fields

### Embedding Validation
- Vector dimension must match model (1536 for text-embedding-3-small)
- Vector values must be floats
- Batch size must be reasonable (e.g., ≤ 100 chunks)

### Qdrant Document Validation
- `id` must match chunk ID
- `vector` dimension must match collection vector_size
- `payload` must include required fields
- `metadata` must be valid JSON

### Pipeline Context Validation
- `context` must be non-empty string (when implemented)
- `chunks` must be list of valid chunk dictionaries
- `query_embedding` must be valid embedding vector

## Status

⚠️ **All data structures are placeholders. Real implementation will be added in future features.**
