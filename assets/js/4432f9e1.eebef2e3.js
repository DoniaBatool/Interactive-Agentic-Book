"use strict";(globalThis.webpackChunkphysical_ai_robotics_book=globalThis.webpackChunkphysical_ai_robotics_book||[]).push([[549],{3890(n,e,i){i.r(e),i.d(e,{assets:()=>r,contentTitle:()=>l,default:()=>p,frontMatter:()=>s,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"modules/vla-capstone","title":"Chapter 5: Vision-Language-Action Capstone","description":"Voice-to-action, intent parsing, planning, navigation, perception, and manipulation for the capstone humanoid project.","source":"@site/docs/modules/vla-capstone.md","sourceDirName":"modules","slug":"/modules/vla-capstone","permalink":"/Interactive-Agentic-Book/docs/modules/vla-capstone","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"vla-capstone","slug":"/modules/vla-capstone","title":"Chapter 5: Vision-Language-Action Capstone","description":"Voice-to-action, intent parsing, planning, navigation, perception, and manipulation for the capstone humanoid project."},"sidebar":"courseSidebar","previous":{"title":"Chapter 4: NVIDIA Isaac AI Brain","permalink":"/Interactive-Agentic-Book/docs/modules/nvidia-isaac"}}');var a=i(4848),o=i(8453);const s={id:"vla-capstone",slug:"/modules/vla-capstone",title:"Chapter 5: Vision-Language-Action Capstone",description:"Voice-to-action, intent parsing, planning, navigation, perception, and manipulation for the capstone humanoid project."},l="Chapter 5: Vision-Language-Action Capstone",r={},c=[{value:"Overview",id:"overview",level:2},{value:"Voice-to-Action Pipeline",id:"voice-to-action-pipeline",level:2},{value:"Intent Parsing &amp; Planning",id:"intent-parsing--planning",level:2},{value:"Navigation &amp; Manipulation Execution",id:"navigation--manipulation-execution",level:2},{value:"Perception Hooks",id:"perception-hooks",level:2},{value:"Safety &amp; Guardrails",id:"safety--guardrails",level:2},{value:"Evaluation &amp; Metrics",id:"evaluation--metrics",level:2},{value:"Demo Tips",id:"demo-tips",level:2},{value:"Recap / Key Outcomes",id:"recap--key-outcomes",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(n){const e={h1:"h1",h2:"h2",header:"header",li:"li",p:"p",ul:"ul",...(0,o.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"chapter-5-vision-language-action-capstone",children:"Chapter 5: Vision-Language-Action Capstone"})}),"\n",(0,a.jsx)(e.h2,{id:"overview",children:"Overview"}),"\n",(0,a.jsx)(e.p,{children:"This capstone ties voice, language, vision, and action to control a humanoid: voice input \u2192 intent \u2192 plan \u2192 navigation/manipulation with safety checks."}),"\n",(0,a.jsx)(e.h2,{id:"voice-to-action-pipeline",children:"Voice-to-Action Pipeline"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Voice capture \u2192 ASR (e.g., Whisper) \u2192 transcript."}),"\n",(0,a.jsx)(e.li,{children:"Intent parsing: map to goals and constraints; confirm critical actions."}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"intent-parsing--planning",children:"Intent Parsing & Planning"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Translate natural language into ROS 2 actions/waypoints/skills."}),"\n",(0,a.jsx)(e.li,{children:"Use planning layer to sequence navigation + manipulation with preconditions."}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"navigation--manipulation-execution",children:"Navigation & Manipulation Execution"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Nav2 for movement; ROS actions for arms/hands; coordinate frames and TF validation."}),"\n",(0,a.jsx)(e.li,{children:"Recovery behaviors for failures (replan, retry, or ask user)."}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"perception-hooks",children:"Perception Hooks"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Vision/LiDAR for object/scene grounding; confidence checks."}),"\n",(0,a.jsx)(e.li,{children:"Use perception outputs to validate goals before executing."}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"safety--guardrails",children:"Safety & Guardrails"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Confirmation for risky tasks; bounding areas; rate limits; watchdogs."}),"\n",(0,a.jsx)(e.li,{children:"Simulation-first testing before real hardware."}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"evaluation--metrics",children:"Evaluation & Metrics"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Task success rate; time-to-complete; safety events; perception confidence."}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"demo-tips",children:"Demo Tips"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Start with simple voice commands (\u201cgo to table\u201d, \u201cpick the cup\u201d)."}),"\n",(0,a.jsx)(e.li,{children:"Show partial progress updates and safe stops."}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"recap--key-outcomes",children:"Recap / Key Outcomes"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"You understand the end-to-end voice-to-action flow with planning and perception."}),"\n",(0,a.jsx)(e.li,{children:"You know how to wire Nav2, manipulation, and safety guardrails."}),"\n",(0,a.jsx)(e.li,{children:"You have metrics to evaluate and iterate on the capstone."}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Integrate personalization and translation toggles; harden testing and demos."}),"\n"]})]})}function p(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(d,{...n})}):d(n)}},8453(n,e,i){i.d(e,{R:()=>s,x:()=>l});var t=i(6540);const a={},o=t.createContext(a);function s(n){const e=t.useContext(o);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:s(n.components),t.createElement(o.Provider,{value:e},n.children)}}}]);